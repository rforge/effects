% !Rnw root = gallery.Rnw



\section{Introduction}\label{sec:intro}
Predictor effect plots \citep{fw19b} provide graphical summaries for fitted regression models with a linear predictor, including linear models, generalized linear models, linear and generalized linear mixed models, and many others.  These graphs are an alternative to tables of fitted coefficients, which can be much harder to interpret than effect plots. Predictor effect plots are implemented in \R{} in the \pkg{effects} package, documented in \citet{fw19}.  This vignette provides many examples of variations on these graphical displays that can be obtained with the \pkg{effects} package.  Many of the details, and more complete descriptions of the data sets used as examples, are provided in the references cited at the end of the vignette.



\subsection{Effects and Predictor Effect Plots}\label{sec:intro2}


We begin with an example of a multiple linear regression, using the \code{Prestige} data set in the \pkg{carData} package:
<<>>=
library("car") # also loads the carData package
Prestige$type <- factor(Prestige$type, levels=c("bc", "wc", "prof"))
lm1 <- lm(prestige ~ education + poly(women, 2) +
                     log(income)*type, data=Prestige)
@
The data, collected circa 1970, pertain to 102 Canadian occupations. The model \code{lm1} is a linear model with response \vn{prestige}, continuous predictors \vn{income}, \vn{education}, and \vn{women}, and the factor predictor \vn{type}, which has three levels. Before fitting the model, we reorder the levels of \vn{type} as \level{bc} (blue-collar), \level{wc} (white-collar),  and \level{prof} (professional and managerial).  The predictor \vn{education} represents itself in the linear model, and so it is both a predictor and a \emph{regressor}, as defined in \citet[Sec.~4.1]{fw19}.  The predictor \vn{income} is represented by the regressor \lcode{income}. The variable \vn{women}, a percentage between 0 and 100, is represented by regressors that define a polynomial of degree 2 using \fn{poly}'s default orthogonal polynomials.  The variable \vn{type} is a factor with three levels, so it is represented by two dummy variables defined by the default contrast-generating function in \R{}, \fn{contr.treatment}.  Finally, the formula includes an interaction between \vn{income} and \vn{type}. defined by multiplying each of the regressor for \vn{income} by each of the regressors that represent \vn{type}.

The usual numeric summary of the fit of \code{lm1} is a table of estimated coefficients, which we obtain via the \fn{S} function in the \pkg{car} package that is similar to, but somewhat more flexible than, the standard \R{} \fn{summary} function:
<<>>=
S(lm1)
@
\begin{itemize}

\item Interpretation of the regression coefficients is straightforward only for the predictor \vn{education}, where an increase of one year of \vn{education}, holding other predictors fixed, corresponds to an estimated expected increase in the response of \Sexpr{round(coef(lm1)[2], 3)} units.  

\item Even ignoring the interaction, the log transformation complicates the interpretation of the effect of \vn{income}.%\footnote{An alternative here is to use logs-base-2 rather than natural logs, in which case the coefficient of log-\vn{income}, again ignoring the interaction, would represent the effect of doubling \vn{income} holding other predictors constant.}

\item The predictor \vn{women} is represented by two regressors, so the effect of \vn{women} requires examining two coefficient estimates that are interpretable only by those knowledgeable about polynomial regression analysis. Even if raw rather than orthogonal polynomial regressors were used, via \code{poly(women, 2, raw=TRUE)} in place of \code{poly(women, 2)}, interpretation of the effect of \vn{women} is complicated.  

\item Understanding the coefficients for the main effect of \vn{type} depends on the contrasts used  to define the effect.  The contrasts can be changed by the user, and the default contrasts in \R{} are different from the default contrasts used by \proglang{SAS} or other programs, so the coefficients cannot be reliably interpreted without information not present in the regression summary.  

\item Finally, the interaction further complicates the interpretation of the effect of either \vn{income} or \vn{type}, because the interaction coefficients need to be interpreted jointly with the main effect coefficients. 

\end{itemize}

\noindent Summarization of the effects of predictors using tables of coefficient estimates is often incomplete.  Effects, and particularly plots of effects, can in many instances  reveal the relationship of the response to the predictors more clearly.  This conclusion is especially true for models with linear predictors that include interactions and multiple-coefficient terms such as regression splines and polynomials, as illustrated in this vignette.
%JF: We don't have an example using regression splines and it would be nice to add one or modify one of the existing examples.

A predictor effect plot summarizes the role of a selected \emph{focal} predictor in a fitted regression model.  The \fn{predictorEffect} function is used to compute the appropriate summary of the regression, and then the \fn{plot} function may be used to graph the resulting object, as in the following example:
<<fig11,include=TRUE,fig.width=5,fig.height=4,fig.show='hide'>>=
library("effects")
e1.lm1 <- predictorEffect("education", lm1)
plot(e1.lm1)
@

\centerline{\includegraphics[width=4in]{figure/fig11-1.pdf}}

\noindent
This graph visualizes the partial slope for \vn{education}, that for each year increase in \vn{education}, the fitted \vn{prestige} increases by \Sexpr{round(coef(lm1)[2], 3)} points, when the other predictors are held fixed.  The intercept of the line, which is outside the range of \vn{education} on the graph, affects only the height of the line, is determined by the choices for averaging over the fixed predictors, but for any choice of averaging method, the slope of the line would be the same. %\footnote{The intercept doesn't actually appear in the graph, because the horizontal axis doesn't extend to $\code{education} = 0$.}  
The shaded area is a pointwise confidence band for the fitted values, based on standard errors computed from the covariance matrix of the fitted regression coefficients. The rug plot at the bottom of the graph shows the location of the \vn{education} values.

The information that is needed to draw the plot is computed by the \fn{predictorEffect} function.
The minimal arguments for \fn{predictorEffect} are the quoted name of a predictor in the model followed by the fitted model object.  The essential purpose of this function is to compute fitted values from the model with \vn{education} varying and all other predictors fixed at typical values \citep[Sec.~4.3]{fw19}.  The command below displays the values of the regressors for which fitted values are computed, including a column of 1s for the intercept:
<<>>=
e1.lm1$model.matrix
@
The focal predictor \vn{education} was evaluated by default at 50 points covering the observed range of values of \vn{education}.  For each value of \vn{education} the remaining regressors have the same fixed values for each fitted value.  The fixed value for \lvn{income} is the logarithm of the sample mean \vn{income}, the fixed values for the regressors for \vn{women} are computed at the mean of \vn{women} in the data, and the fixed values for the regressors for \vn{type} effectively take a weighted average of the fitted values at the three levels of \vn{type}, with weights proportional to the number of cases in each level of the factor.%\footnote{Although the treatment of the factor \vn{type} sounds complicated, weighting averaging is achieved simply by computing the mean of each dummy regressor, which then corresponds to the proportion of cases coded 1 for that dummy regressor. This approach works more generally for other kinds of contrasts.}  
Differences in the fitted values are due to \vn{education} alone because all the other predictors, and their corresponding regressors, are fixed.  Thus the output gives the partial effect of \vn{education} with all other predictors fixed.%\footnote{Such effects are often called \emph{marginal effects}. We prefer the term \emph{partial effects} because it implies holding other predictors constant.}

The computed fitted values can be viewed by printing the \class{eff} object returned by \fn{predictorEffect}, by summarizing the object, or by converting it to a data frame:
<<>>=
e1.lm1
summary(e1.lm1)
as.data.frame(e1.lm1)
@
The values in the column \vn{education} are the values the focal predictor.  The remaining columns are the fitted values, their standard errors, and lower and upper end points of 95\% confidence intervals for the fitted values.
The \emph{predictor effect plot} is simply a graph of the fitted values on the vertical axis versus the focal predictor on the horizontal axis.  For a continuous focal predictor such as \vn{education}, a line, in this case, a straight line, is drawn connecting the fitted values.

We turn next to the predictor effect plot for \vn{income}.  According to the regression model, the effect of \vn{income} may depend on \vn{type} due to the interaction between the two predictors, so simply averaging over \vn{type} would be misleading.  Rather, we should allow both \vn{income} and \vn{type} to vary, fixing the other predictors at their means or other typical values.  This would require evaluating the model at $50 \times 3 = 150$ combinations of the predictors, but to save space we will only evaluate \vn{income} at five values using the \ar{focal.levels} argument, thus evaluating only $5 \times 3 = 15$ fitted values.
<<>>=
e2.lm1 <- predictorEffect("income", lm1, focal.levels=5)
as.data.frame(e2.lm1)
@

To draw the predictor effects plot we recalucluate the fitted values using the default \code{focal.values=50} to get more accurate curves:
<<fig12,include=TRUE,fig.width=5,fig.height=5,fig.show='hide'>>=
plot(predictorEffect("income", lm1, focal.levels=50), 
     lines=list(multiline=TRUE))
@

\centerline{\includegraphics[width=4in]{figure/fig12-1.pdf}}

\noindent
The focal predictor \vn{income} is displayed on the horizontal axis.  There is a separate line shown for the fitted values at each level of \vn{type}.  The lines are curved rather than straight  because \vn{income} appears in the model in log-scale but is displayed in the predictor effect plot in arithmetic (i.e., dollar) scale.  The lines in the graph are not parallel because of the interaction between \lvn{income} and \vn{type}.  For $\vn{type} = \level{prof}$, the fitted values of \vn{prestige} are relatively high for lower values of \vn{income}, and are relatively less affected by increasing values of \vn{income}.  If the number of levels for evaluating \vn{income} were five rather than 50 the lines on the plot would be somewhat less accurate.%\footnote{The predictors \vn{type} and \vn{income} are related, however, with for example \level{prof} having relatively high incomes. As a consequence, some regions of the graph, such as high-income \level{bc} occupations, are essentially devoid of data, and the fitted regression lines in these regions represent extrapolation beyond the data. We can effectively visualize this characteristic of the data by adding partial residuals to the predictor effect plot, a subject that we address in Section~\ref{sec:res}. We invite the reader to do this for the predictor \vn{income} in model \code{e2.lm1}.}

The predictor effect plot for \vn{type} uses the same fitted values as the plot for \vn{income}, but we now get five lines, one for each of the values of \vn{income} selected by the \fn{predictorEffect} function:
<<fig13,include=TRUE,fig.width=5,fig.height=5,fig.show='hide'>>=
plot(predictorEffect("type", lm1), lines=list(multiline=TRUE))
@

\centerline{\includegraphics[width=4in]{figure/fig13-1.pdf}}

\noindent
Here we use both the \fn{predictorEffect} and \fn{plot} functions in the same command.
Because the horizontal axis is now a factor, the fitted values are displayed explicitly as points, and the lines that join the points are merely a visual aid representing  \emph{profiles} of fitted values.  Fitted \vn{prestige} increases with \vn{income} for all levels of \vn{type}, but, as we found before, when $\vn{type}=\level{prof}$, fitted \vn{prestige} is relatively high for lower \vn{income}.

These initial examples use only default arguments for \fn{predictorEffect} and \fn{plot}, apart from the \code{multiline} argument to \fn{plot} to put all the fitted lines in the same graph. We explain how to customize predictor effect plots in subsequent sections of this vignette.

\subsection{General Outline for Constructing Predictor Effect Plots}

Using the \pkg{effects} package to draw plots usually entails the following steps:
\begin{enumerate}

\item Fit a regression model with a linear predictor.  The package supports models created by \fn{lm}, \fn{glm}, \fn{lmer} and \fn{glmer} in the \pkg{lme4} package, \fn{lme} in the \pkg{nlme} package, and many other regression-modeling functions (see \code{?Effect}).

\item The regression model created in the first step is then used as input to either  \fn{predictorEffect}, to get the effects for one predictor, or \vn{predictorEffects}, to get effects for one or more predictors. These functions do the averaging needed to get fitted values that will ultimately be plotted. There are many arguments for customizing the computation of the effects. The two predictor effect functions call the more basic \fn{Effect} function, and almost all of the material in this vignette applies to \fn{Effect} as well.% (see in particular Section~\ref{sec:Effect}).

\item Use the generic \fn{plot} function to draw a graph or graphs based on the object created in Step 2.

\end{enumerate}

% In Section~\ref{sec:eff} we discuss the functions described in step 2 above, and many of the arguments for their use.  In Section~\ref{sec:plot} we discuss and provide examples of the many arguments to the \fn{plot} method for effects objects.  Adding residuals to effect plots is discussed in Section~\ref{sec:res}.  Finally in Section~\ref{sec:emmeans} we discuss the connection between the \pkg{effects} package and the \pkg{emmeans} package \citep{lenth18} that provides tests that can complement predictor effect plots.
% JF: I've commented this out because it's disorganized and incomplete, and because I don't think that it adds anything to the table of contents.

\subsection{How \fn{predictorEffect} Chooses Conditioning Predictors}\label{sec:eff}

Suppose that you select one {focal} predictor for which you want to draw a predictor effect plot.  The \fn{predictorEffect} function divides the predictors in a model formula into three groups:
\begin{enumerate}

\item The focal predictor.

\item The \emph{conditioning group}, consisting of all predictors with at least one interaction in common with the focal predictor.

\item The \emph{fixed group}, consisting of all other predictors, that is, those  with no interactions in common with the focal predictor.

\end{enumerate}

\noindent The predictors in the fixed group are all evaluated at typical values, usually their means, effectively averaging out the influence of these predictors on the fitted value.  Fitted values are computed for all combinations of levels of the predictors in the conditioning group, with each continuous predictor in the conditioning group replaced by a few discrete values spanning the range of the predictor, for example, replacing years of \vn{education} by a discrete variable with the values 8, 12, and 16 years.

Suppose that we fit a model with \R{} formula
\begin{equation}
\Rmod{y}{x1 + x2 + x3 + x4 + x2:x3 + x2:x4}\label{eq1}
\end{equation}
or, equivalently,
\begin{equation*}
\Rmod{y}{x1 + x2*x3 + x2*x4}
\end{equation*}
There are four predictor effect plots for this model, one for each predictor selected in turn as the focal predictor:

\begin{center}
\begin{tabular}{ccc}\hline
Focal & Conditioning & Fixed\\
Predictor & Group & Group\\ \hline
\vn{x1} &  none& \vn{x2}, \vn{x3}, \vn{x4} \\
\vn{x2} & \vn{x3}, \vn{x4} & \vn{x1} \\
\vn{x3} &  \vn{x2} & \vn{x1}, \vn{x4} \\
\vn{x4} &  \vn{x2}& \vn{x1} \vn{x3} \\ \hline
\end{tabular}
\end{center}

\noindent
The predictor \vn{x1} does not interact with any of the other predictors, so its conditioning set is empty and all the remaining predictors are averaged over; \vn{x2} interacts with both \vn{x3} and \vn{x4}; \vn{x3} interacts only with \vn{x2}; and \vn{x4} interacts with \code{x2}.

\subsection{The \fn{Effect} Function}\label{sec:Effect}

Prior to late 2018, the primary function in \pkg{effects} for computing and displaying effects was the \fn{Effect} function.\footnote{The \pkg{effects} package also includes the older \fn{allEffects} function, which computes effects for each high-order term in a model with a linear predictor. As we explain in \citet{fw19b}, we prefer predictor effects to high-order term effects, and so, although its use is similar to \fn{predictorEffects}, we won't describe \fn{allEffects} in this vignette. There is also an older \fn{effect} function (with a lowercase ``\code{e}''), which is a less flexible version of \fn{Effect}, and which calls \fn{Effect} to perform computations; \fn{effect} is retained only for backwards comparability.}  Whereas the \fn{predictorEffect} function automatically determines the conditioning group and the fixed group of predictors, the \fn{Effect} function puts that burden on the user.
Each call to \fn{predictorEffect} is equivalent to a specific call to the \fn{Effect} function as follows.  Suppose that \vn{m} is the fitted model produced by the formula in (\ref{eq1}); then
\begin{description}

\item[] \code{predictorEffect("x1", m)} is equivalent to \code{Effect("x1", m)};

\item[] \code{predictorEffect("x2", m)} is equivalent to \code{Effect(c("x2", "x3", "x4"), m)};

\item[] \code{predictorEffect("x3", m)} is equivalent to \code{Effect(c("x3", "x2"), m)}; and


\item[] \code{predictorEffect("x4", m)} is equivalent to \code{Effect(c("x4", "x2"), m)}.

\end{description}

The \fn{predictorEffect} function determines the correct call to \fn{Effect} based on the choice of focal predictor and on the structure of main effects and interactions in the linear predictor for the model.  It then uses the \fn{Effect} function to do the computing.  As a result, most of the arguments to \fn{predictorEffect} are documented in \code{help("Effect")} rather than in \code{help("predictorEffect")}.

\subsection{The \fn{predictorEffects} Function}

This function, whose name ends with the plural ``\code{plots}", computes the values needed for one or more predictor effect plots, and by default for \emph{all} of the predictors in the model.  For example, the following command produces all of the predictor effect plots for the model we fit to the \code{Prestige} data:
<<fig14,include=TRUE,fig.width=7,fig.height=8,fig.show='hide'>>=
eall.lm1 <- predictorEffects(lm1)
plot(eall.lm1)
@

\centerline{\includegraphics[width=0.95\textwidth]{figure/fig14-1.pdf}}

\noindent
The predictor effect plots for this model are displayed in an array of graphs.  The plots for \vn{income} and \vn{type} have a separate panel for each level of the conditioning variable because the default argument \ar{lines=list(multiline=FALSE)} was used.  Confidence bounds are shown by default when \ar{multiline=FALSE}.

The resulting object \code{eall.lm1} is a list with four elements, where \code{eall.lm1[[1]]} is the summary for the first predictor effect plot, \code{eall.lm1[[2]]} for the second plot, and so on.  The following equivalent commands draw the same array of predictor effect plots:
<<eval=FALSE>>=
plot(eall.lm1)
plot(predictorEffects(lm1))
plot(predictorEffects(lm1, ~ income + education + women + type))
@
If you want only the predictor effect plots for \vn{type} and \vn{education}, in that order, you could enter
<<eval=FALSE>>=
plot(predictorEffects(lm1, ~ type + education))
@
Similarly, the commands
<<eval=FALSE>>=
plot(predictorEffects(lm1, ~ women))
plot(predictorEffects(lm1)[[3]])
plot(predictorEffect("women",lm1))
@
all produce the same graph, the predictor effect plot for \vn{women}.

Predictor effect plots in an array can be a useful shortcut for drawing many graphs quickly, but can lead to problems with the displayed graphs. For example, the horizontal axis labels for the plot for \vn{income} are overprinted, and the labels at the top of the plots for \vn{type} with conditioning variable \vn{income} are larger than the available space.  These problems can often be fixed using optional arguments described later in this vignette.
